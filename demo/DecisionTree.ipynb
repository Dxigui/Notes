{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å†³ç­–æ ‘\n",
    "å†³ç­–æ ‘(decision tree)æ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»å’Œå›å½’æ–¹æ³•.åœ¨åˆ†ç±»é—®é¢˜ä¸­,å†³ç­–æ ‘åœ¨å¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±»è¿‡ç¨‹ä¸­å¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸€ç§ `if-then` è§„åˆ™çš„é›†åˆ.  \n",
    "å†³ç­–æ ‘ä¼˜ç‚¹:  \n",
    "* æœ‰è‰¯å¥½çš„å¯è¯»æ€§\n",
    "* åˆ†ç±»é€Ÿåº¦å¿«  \n",
    "\n",
    "å†³ç­–æ ‘çš„å­¦ä¹ åŒ…æ‹¬:  \n",
    "* ç‰¹å¾é€‰æ‹©\n",
    "* å†³ç­–æ ‘çš„ç”Ÿæˆ\n",
    "* å†³ç­–æ ‘çš„ä¿®å‰ª  \n",
    "\n",
    "å†³ç­–æ ‘çš„ç®—æ³•:  \n",
    "* ID3 : ä¿¡æ¯å¢ç›Š\n",
    "* C4.5 : ä¿¡æ¯å¢ç›Šæ¯”\n",
    "* CART : gini æŒ‡æ•°\n",
    "\n",
    "## ç‰¹å¾é€‰æ‹©\n",
    "### 1. ä¿¡æ¯å¢ç›Šé€‰æ‹©ç‰¹å¾\n",
    "é€‰æ‹©åˆé€‚çš„ç‰¹å¾ä½œä¸ºæ ¹èŠ‚ç‚¹èƒ½æå‡åˆ†ç±»æ•ˆæœ,ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ä¸ºæœ€ä¼˜ç‰¹å¾.  \n",
    "ä¿¡æ¯å¢ç›Š = ç»éªŒç†µ - æ¡ä»¶ç»éªŒç†µ  \n",
    "$ g(D,A) = H(D) - H(D|A) $  \n",
    "* ç»éªŒç†µ: H(D) ä¸ºæ•°æ®é›† D çš„ç»éªŒç†µ  \n",
    "$ H(D) = -\\sum_{i=1}^{n}p_i{log_2{p_i}} $  \n",
    "$ p_i = P(X=x_i),i=1,2,...,n $  \n",
    "* ç»éªŒæ¡ä»¶ç†µ: H(Y|X) ç‰¹å¾ X å¯¹æ•°æ®é›† D çš„ç»éªŒç†µ  \n",
    "$ H(Y|X) = \\sum_{i=1}^{n}p_iH(Y|X=x_i) $  \n",
    "\n",
    "ç¤ºä¾‹:  \n",
    "è®­ç»ƒæ•°æ®é›† D,|D| è¡¨ç¤ºå…¶æ ·æœ¬å®¹é‡,å³æ ·æœ¬ä¸ªæ•°.è®¾ K ä¸ªç±» $ C_k $,k=1,2,...,K,$ |C_k| $ ä¸ºå±äºç±» $ C_k $ çš„æ ·æœ¬ä¸ªæ•°,$ \\sum_{k=1}^{K}|C_k|=|D| $.ç¤¾ç‰¹å¾ A æœ‰ n ä¸ªä¸åŒçš„å–å€¼ {$ a_1,a_2,...,a_n $},æ ¹æ®ç‰¹å¾ A çš„å–å€¼å°† D åˆ’åˆ†ä¸º n ä¸ªå­é›† {$ D_1,D_2,...,D_3 $},$ |D_i| $ ä¸º $ D_i $ çš„æ ·æœ¬ä¸ªæ•°,$ \\sum_{i=1}^{n}|D_i|=|D| $,å­é›† $ D_i $ ä¸­æ•°æ®ç±» $ C_k $ çš„æ ·æœ¬çš„é›†åˆä¸º $ D_{ik} $,å³ $ D_{ik}={D_i}\\bigcap{C_k},{D_{ik}} ä¸º D_{ik} $ çš„æ ·æœ¬ä¸ªæ•°.  \n",
    "1. è®¡ç®—æ•°æ®é›† D çš„ç»éªŒç†µ H(D)  \n",
    "$ H(D) = -\\sum_{k=1}^{k}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|} $  \n",
    "2. è®¡ç®—ç‰¹å¾ A å¯¹æ•°æ®é›† D çš„ç»éªŒæ¡ä»¶ç†µ H(D|A)  \n",
    "$ H(D|A) = \\sum_{i=1}^{n}\\frac{|C_i|}{|D|}H(D_i) = -\\sum_{i=1}^{n}\\frac{|C_i|}{|D|}\\sum_{k=1}^{k}\\frac{|D_ik|}{|Di|}log_2\\frac{|D_ik|}{|Di|} $  \n",
    "3. è®¡ç®—ä¿¡æ¯å¢ç›Š  \n",
    "$ g(D,A) = H(D) - H(D|A) $  \n",
    "\n",
    "### 2. ä¿¡æ¯å¢ç›Šæ¯”é€‰æ‹©ç‰¹å¾  \n",
    "ä¿¡æ¯å¢ç›Šæ¯”æ˜¯å¯¹ä¿¡æ¯å¢ç›Šçš„æ ¡æ­£.å½“åˆ†ç±»å›°éš¾,è®­ç»ƒæ•°æ®é›†çš„ç»éªŒç†µè¿‡å¤§,ä¿¡æ¯å¢ç›Šå€¼ä¼šåå¤§,åä¹‹åå°,è¿™æ—¶å°±éœ€è¦å¯¹å…¶è¿›è¡Œæ ¡æ­£.  \n",
    "* ä¿¡æ¯å¢ç›Šæ¯” = ä¿¡æ¯å¢ç›Š / ç»éªŒç†µ  \n",
    "$ g_R(D,A) = \\frac{g(D,A)}{H(D)} $  \n",
    "\n",
    "## å†³ç­–æ ‘çš„ç”Ÿæˆ  \n",
    "### ID3 ç®—æ³• \n",
    "ID3 ç®—æ³•æ˜¯åŸºäºä¿¡æ¯å¢ç›Šå‡†åˆ™é€‰æ‹©ç‰¹å¾æ¥æ„å»ºå†³ç­–æ ‘çš„å„ä¸ªç»“ç‚¹,é€’å½’ç”ŸæˆèŠ‚ç‚¹.  \n",
    "ä»æ ¹èŠ‚ç‚¹å¼€å§‹,å¯¹æ¯ä¸ªç»“ç‚¹éƒ½è®¡ç®—ç‰¹å¾çš„ä¿¡æ¯å¢ç›Š,é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ä½œä¸ºç»“ç‚¹çš„ç‰¹å¾,è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼å»ºç«‹å­ç»“ç‚¹;  \n",
    "æ„å»ºå†³ç­–æ—¶(æ•°æ®é›† D,ç‰¹å¾é›† A, é˜ˆå€¼ $ \\varepsilon $, å†³ç­–æ ‘ T):  \n",
    "1. å½“ D æ‰€æœ‰å®ä¾‹å±äºåŒä¸€ç±» $ C_k $,åˆ™ T ä¸ºå•ç»“ç‚¹æ ‘,å¹¶å°†ç±» $ C_k $ ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°,è¿”å› T;\n",
    "2. è‹¥ A=$ \\varnothing $ ,åˆ™ T ä¸ºå•ç»“ç‚¹æ ‘,å¹¶å°† D ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±» $ C_k $ ä½œä¸ºè¯¥ç»“ç‚¹çš„ç±»æ ‡è®°,è¿”å› T;\n",
    "3. å¦åˆ™,è®¡ç®— A ä¸­å„ä¸ªç‰¹å¾å¯¹ D çš„ä¿¡æ¯å¢ç›Š,é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ $ A_g $;\n",
    "4. å¦‚æœ $ A_g $ çš„ä¿¡æ¯å¢ç›Šå°äºé˜ˆå€¼ $ \\varepsilon $,åˆ™ç½® T ä¸ºå¤§å•ç»“ç‚¹æ ‘,å¹¶å°† Dä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±» $ C_k $ ä½œä¸ºè¯¥ç»“ç‚¹çš„ç±»æ ‡è®°,è¿”å› T\n",
    "5. å¦åˆ™,å¯¹ $ A_g $ çš„æ¯ä¸€ä¸ªå¯èƒ½çš„å€¼ $ a_i,ä¾ A_g=a_i $ å°† D åˆ†å‰²ä¸ºè‹¥å¹²éç©ºå­é›† $ D_i,å°† D_i $ ä¸­å®ä¾‹æœ€å¤§çš„ç±»ä½œä¸ºç±»æ ‡è®°,è¿”å› T;\n",
    "6. å¯¹ç¬¬iä¸ªå­ç»“ç‚¹,ä»¥ $ D_i $ ä¸ºè®­ç»ƒé›†,ä»¥A-{$ A_g $}ä¸ºç‰¹å¾é›†,é€’å½’åœ°è°ƒç”¨æ­¥(1)~æ­¥(5),å¾—åˆ°å­æ ‘ $ T_i $,è¿”å› $ T_i $  \n",
    "\n",
    "### C4.5 ç®—æ³•\n",
    "C4.5 ç®—æ³•æ˜¯åŸºäºä¿¡æ¯å¢ç›Šæ¯”æ„å»ºå†³ç­–æ ‘\n",
    "## å†³ç­–æ ‘å‰ªæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    datasets = [['é’å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],\n",
    "               ['é’å¹´', 'å¦', 'å¦', 'å¥½', 'å¦'],\n",
    "               ['é’å¹´', 'æ˜¯', 'å¦', 'å¥½', 'æ˜¯'],\n",
    "               ['é’å¹´', 'æ˜¯', 'æ˜¯', 'ä¸€èˆ¬', 'æ˜¯'],\n",
    "               ['é’å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],\n",
    "               ['ä¸­å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],\n",
    "               ['ä¸­å¹´', 'å¦', 'å¦', 'å¥½', 'å¦'],\n",
    "               ['ä¸­å¹´', 'æ˜¯', 'æ˜¯', 'å¥½', 'æ˜¯'],\n",
    "               ['ä¸­å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],\n",
    "               ['ä¸­å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],\n",
    "               ['è€å¹´', 'å¦', 'æ˜¯', 'éå¸¸å¥½', 'æ˜¯'],\n",
    "               ['è€å¹´', 'å¦', 'æ˜¯', 'å¥½', 'æ˜¯'],\n",
    "               ['è€å¹´', 'æ˜¯', 'å¦', 'å¥½', 'æ˜¯'],\n",
    "               ['è€å¹´', 'æ˜¯', 'å¦', 'éå¸¸å¥½', 'æ˜¯'],\n",
    "               ['è€å¹´', 'å¦', 'å¦', 'ä¸€èˆ¬', 'å¦'],\n",
    "               ]\n",
    "    columns = ['å¹´é¾„', 'æœ‰å·¥ä½œ', 'æœ‰è‡ªå·±çš„æˆ¿å­', 'ä¿¡è´·æƒ…å†µ', 'ç±»åˆ«']\n",
    "    # è¿”å›æ•°æ®é›†å’Œæ¯ä¸ªç»´åº¦çš„åç§°\n",
    "    return datasets, columns\n",
    "datasets, columns = create_data()\n",
    "train_data = pd.DataFrame(datasets, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empiricalEntropy(train_data, label):\n",
    "    \"\"\"\n",
    "    ç»éªŒç†µ\n",
    "    train_data: æ•°æ®é›†\n",
    "    label: ç›®æ ‡é›†\n",
    "    \"\"\"\n",
    "    data_length = len(train_data)\n",
    "    labels_count = train_data[label].value_counts()\n",
    "    pi = [label / data_length for label in labels_count]\n",
    "    entropy = -sum([(p * log(p, 2)) for p in pi])\n",
    "    return entropy\n",
    "\n",
    "def empiricalConditionalEntropy(train_data, columns):\n",
    "    \"\"\"\n",
    "    æ¡ä»¶ç»éªŒç†µ\n",
    "    \"\"\"\n",
    "    data_length = len(train_data)\n",
    "    labels = pd.unique(train_data[columns[-1]])\n",
    "    labels_length = len(labels)\n",
    "    result = {}\n",
    "    for col in columns[:-1]:\n",
    "        attr_name = pd.unique(train_data[col])\n",
    "        attr_count = train_data[col].value_counts()\n",
    "        tmp = []\n",
    "        for name, count in zip(attr_name, attr_count):\n",
    "            # ç‰¹å¾çš„ä¸€ä¸ªå±æ€§å±äºæŸç±»çš„æ¦‚ç‡\n",
    "            pi = [len(train_data[train_data[col] == name][train_data[columns[-1]] == label]) / count for label in labels]\n",
    "            entropy = -sum([p * log(p, 2) for p in pi if p != 0.0]) * (count / data_length)\n",
    "            tmp.append(entropy)\n",
    "        result[col] = sum(tmp)\n",
    "    max_entropy = sorted(result.items(), key=lambda x: x[1])[0]\n",
    "    return max_entropy\n",
    "\n",
    "def infoGain(emp_en, con_en):\n",
    "    return emp_en - con_en\n",
    "\n",
    "def main(train_data, label, columns):\n",
    "    columns = columns + [label]\n",
    "    emp_en = empiricalEntropy(train_data, label)\n",
    "    con_en = empiricalConditionalEntropy(train_data, columns)\n",
    "    result = infoGain(emp_en, con_en[1])\n",
    "    text = 'ç‰¹å¾({})çš„ä¿¡æ¯å¢ç›Šæœ€å¤§ä¸º{}ï¼Œé€‰æ‹©ä¸ºæ ¹èŠ‚ç‚¹ç‰¹å¾'.format(con_en[0], result)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxigui/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ç‰¹å¾(æœ‰è‡ªå·±çš„æˆ¿å­)çš„ä¿¡æ¯å¢ç›Šæœ€å¤§ä¸º0.4199730940219749ï¼Œé€‰æ‹©ä¸ºæ ¹èŠ‚ç‚¹ç‰¹å¾'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(train_data, 'ç±»åˆ«', ['å¹´é¾„', 'æœ‰å·¥ä½œ', 'æœ‰è‡ªå·±çš„æˆ¿å­', 'ä¿¡è´·æƒ…å†µ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ„å»ºå†³ç­–æ ‘\n",
    "1. ID3 ç®—æ³•ç”Ÿæˆå†³ç­–æ ‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label:': self.label, 'feature:': self.feature,\n",
    "                       'tree:': self.tree}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "    \n",
    "    def predict(self, feature):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[feature[self.feature]].predict[feature]\n",
    "\n",
    "class DTree(object):\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def empiricalEntropy(train_data, label):\n",
    "        \"\"\"\n",
    "        ç»éªŒç†µ\n",
    "        train_data: æ•°æ®é›†\n",
    "        label: ç›®æ ‡\n",
    "        \"\"\"\n",
    "        data_length = len(train_data)\n",
    "        labels_count = train_data[label].value_counts()\n",
    "        pi = [label / data_length for label in labels_count]\n",
    "        entropy = -sum([(p * log(p, 2)) for p in pi])\n",
    "        return entropy\n",
    "\n",
    "    def empiricalConditionalEntropy(self, train_data, columns):\n",
    "        \"\"\"\n",
    "        æ¡ä»¶ç»éªŒç†µ\n",
    "        \"\"\"\n",
    "        data_length = len(train_data)\n",
    "        labels = pd.unique(train_data[columns[-1]])\n",
    "        labels_length = len(labels)\n",
    "        result = {}\n",
    "        for col in columns[:-1]:\n",
    "            attr_name = pd.unique(train_data[col])\n",
    "            attr_count = train_data[col].value_counts()\n",
    "            # ç‰¹å¾ a çš„æ¡ä»¶ç»éªŒç†µ\n",
    "            tmp = []\n",
    "            for name, count in zip(attr_name, attr_count):\n",
    "                # ç‰¹å¾çš„ä¸€ä¸ªå±æ€§å±äºæŸç±»çš„æ¦‚ç‡\n",
    "                pi = [len(train_data[train_data[col] == name][train_data[columns[-1]] == label]) / count for label in labels]\n",
    "                entropy = -sum([p * log(p, 2) for p in pi if p != 0.0]) * (count / data_length)\n",
    "                tmp.append(entropy)\n",
    "            result[col] = sum(tmp)\n",
    "        max_entropy = sorted(result.items(), key=lambda x: x[1])[0]\n",
    "        return max_entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def infoGain(emp_en, con_en):\n",
    "        \"\"\"\n",
    "        ä¿¡æ¯å¢ç›Š\n",
    "        \"\"\"\n",
    "        return emp_en - con_en\n",
    "    \n",
    "    def maxInfoGain(self, train_data, label):\n",
    "        columns = list(train_data.columns)\n",
    "        index = columns.index(label)\n",
    "        columns = columns + [columns.pop(index)]\n",
    "        emp_en = empiricalEntropy(train_data, label)\n",
    "        con_en = self.empiricalConditionalEntropy(train_data, columns)\n",
    "        result = infoGain(emp_en, con_en[1])\n",
    "        # best = 'ç‰¹å¾({})çš„ä¿¡æ¯å¢ç›Šæœ€å¤§ä¸º{}ï¼Œé€‰æ‹©ä¸ºæ ¹èŠ‚ç‚¹ç‰¹å¾'.format(con_en[0], result)\n",
    "        return con_en[0], result\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input: æ•°æ®é›† D, ç‰¹å¾é›† A, é˜ˆå€¼ eta\n",
    "        output: å†³ç­–æ—¶ T\n",
    "        \"\"\"\n",
    "        # 1,è‹¥Dä¸­å®ä¾‹å±äºåŒä¸€ç±»Ckï¼Œåˆ™Tä¸ºå•èŠ‚ç‚¹æ ‘ï¼Œå¹¶å°†ç±»Ckä½œä¸ºç»“ç‚¹çš„ç±»æ ‡è®°ï¼Œè¿”å›T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        label = train_data.columns[-1]\n",
    "        \n",
    "        # å½“ D æ‰€æœ‰å®ä¾‹å±äºåŒä¸€ç±»  ğ¶ğ‘˜ ,åˆ™ T ä¸ºå•ç»“ç‚¹æ ‘,å¹¶å°†ç±»  ğ¶ğ‘˜  ä½œä¸ºè¯¥èŠ‚ç‚¹çš„ç±»æ ‡è®°,è¿”å› T;\n",
    "        if len(y_train.value_counts) == 1:\n",
    "            return TreeNode(root=True, label=y_train.iloc[0])\n",
    "        \n",
    "        # è‹¥ A= âˆ…  ,åˆ™ T ä¸ºå•ç»“ç‚¹æ ‘,å¹¶å°† D ä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»  ğ¶ğ‘˜  ä½œä¸ºè¯¥ç»“ç‚¹çš„ç±»æ ‡è®°,è¿”å› T;\n",
    "        if len(features) == 0:\n",
    "            return TreeNode(root=True, label=train_data.iloc[:,-1].value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        #å¦åˆ™,è®¡ç®— A ä¸­å„ä¸ªç‰¹å¾å¯¹ D çš„ä¿¡æ¯å¢ç›Š,é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾  ğ´ğ‘” ;\n",
    "        max_feature, max_info_gain = self.maxInfoGain(train_data, label)\n",
    "        \n",
    "        # å¦‚æœ  ğ´ğ‘”  çš„ä¿¡æ¯å¢ç›Šå°äºé˜ˆå€¼  ğœ€ ,åˆ™ç½® T ä¸ºå¤§å•ç»“ç‚¹æ ‘,å¹¶å°† Dä¸­å®ä¾‹æ•°æœ€å¤§çš„ç±»  ğ¶ğ‘˜  ä½œä¸ºè¯¥ç»“ç‚¹çš„ç±»æ ‡è®°,è¿”å› T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return TreeNode(root=True, label=y_train.value_counts().values_sort(asceding=False).index[0])\n",
    "        \n",
    "        # å¦åˆ™,å¯¹  ğ´ğ‘”  çš„æ¯ä¸€ä¸ªå¯èƒ½çš„å€¼  ğ‘ğ‘–,ä¾ğ´ğ‘”=ğ‘ğ‘–  å°† D åˆ†å‰²ä¸ºè‹¥å¹²éç©ºå­é›†  ğ·ğ‘–,å°†ğ·ğ‘–  ä¸­å®ä¾‹æœ€å¤§çš„ç±»ä½œä¸ºç±»æ ‡è®°,è¿”å› T;\n",
    "        tree_node = TreeNode(root=False, feature_name=max_feature, feature=max_f)\n",
    "        data = train_data.drop(max_feature, axis=1)\n",
    "        # å¯¹ç¬¬iä¸ªå­ç»“ç‚¹,ä»¥  ğ·ğ‘–  ä¸ºè®­ç»ƒé›†,ä»¥A-{ ğ´ğ‘” }ä¸ºç‰¹å¾é›†,é€’å½’åœ°è°ƒç”¨æ­¥(1)~æ­¥(5),å¾—åˆ°å­æ ‘  ğ‘‡ğ‘– ,è¿”å›  ğ‘‡ğ‘– \n",
    "        # é€’å½’ç”Ÿæˆæ ‘\n",
    "        sub_tree = self.train(data)\n",
    "        tree_node.add_node(sub_tree)\n",
    "        return tree_node\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    return data[:, :2], data[:, -1]\n",
    "\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pic = export_graphviz(clf, out_file=\"mytree.pdf\")\n",
    "with open('mytree.pdf') as f:\n",
    "    dot_graph = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphviz.Source(dot_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
